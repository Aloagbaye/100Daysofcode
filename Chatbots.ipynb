{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "424ec05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4fa54718",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a382abaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON\n",
      "am AUX\n",
      "learning VERB\n",
      "how SCONJ\n",
      "to PART\n",
      "build VERB\n",
      "chatbots NOUN\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'I am learning how to build chatbots') #Creates a doc object\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_) #prints the text and POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eed4ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My PRON\n",
      "name NOUN\n",
      "is AUX\n",
      "Israel PROPN\n",
      ", PUNCT\n",
      "what PRON\n",
      "about ADP\n",
      "you PRON\n",
      "? PUNCT\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'My name is Israel, what about you?') #Creates a doc object\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_) #prints the text and POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41e7ddde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Google PROPN NNP compound Xxxxx True False\n",
      "release release NOUN NN ROOT xxxx True False\n",
      "\" \" PUNCT `` punct \" False False\n",
      "Move Move PROPN NNP nmod Xxxx True True\n",
      "Mirror Mirror PROPN NNP appos Xxxxx True False\n",
      "\" \" PUNCT '' punct \" False False\n",
      "AI AI PROPN NNP compound XX True False\n",
      "experiment experiment NOUN NN appos xxxx True False\n",
      "that that PRON WDT nsubj xxxx True True\n",
      "matches match VERB VBZ relcl xxxx True False\n",
      "your your PRON PRP$ poss xxxx True True\n",
      "pose pose NOUN NN dobj xxxx True False\n",
      "from from ADP IN prep xxxx True True\n",
      "80,000 80,000 NUM CD nummod dd,ddd False False\n",
      "images image NOUN NNS pobj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Google release \"Move Mirror\" AI experiment that matches your pose from 80,000 images')\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bca0203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(text):        \n",
    "    sent = []\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        sent.append(word.lemma_)\n",
    "    return \" \".join(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b36bf031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google release \" Move Mirror \" AI experiment that match your pose from 80,000 image'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cb23a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conference_help_text = ('Gus is helping organize a developer'\n",
    "                        'conference on Applications of Natural Language'\n",
    "                        ' Processing. He keeps organizing local Python meetups'\n",
    "                        ' and several internal talks at his workplace.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0baa4a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conference_help_doc = nlp(conference_help_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1173b146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gus Gus\n",
      "is be\n",
      "helping helping\n",
      "organize organize\n",
      "a a\n",
      "developerconference developerconference\n",
      "on on\n",
      "Applications application\n",
      "of of\n",
      "Natural Natural\n",
      "Language Language\n",
      "Processing Processing\n",
      ". .\n",
      "He he\n",
      "keeps keep\n",
      "organizing organize\n",
      "local local\n",
      "Python Python\n",
      "meetups meetup\n",
      "and and\n",
      "several several\n",
      "internal internal\n",
      "talks talk\n",
      "at at\n",
      "his his\n",
      "workplace workplace\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for token in conference_help_doc:\n",
    "    print (token, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d76248a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Google\n",
      "release release\n",
      "\" \"\n",
      "Move Move\n",
      "Mirror Mirror\n",
      "\" \"\n",
      "AI AI\n",
      "experiment experiment\n",
      "that that\n",
      "matches match\n",
      "your your\n",
      "pose pose\n",
      "from from\n",
      "80,000 80,000\n",
      "images image\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print (token, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b0c51e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastest\n",
      "fastest\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import *\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "print(porter_stemmer.stem(\"fastest\"))\n",
    "print(snowball_stemmer.stem(\"fastest\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23e72f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine Dragons ORG\n"
     ]
    }
   ],
   "source": [
    "my_string1 = u\"Imagine Dragons are the best band.\"\n",
    "my_string2 = u\"Imagine dragons come and take over the city.\"\n",
    "doc1 = nlp(my_string1)\n",
    "doc2 = nlp(my_string2)\n",
    "for ent in doc1.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d260b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc2.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62315c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'see', 'have', 'mostly', 'ten', 'besides', 'wherever', '’s', 'these', '’re', 'other', 'two', 'themselves', 'still', 'might', 'eight', 'himself', 'few', 'therefore', 'thereafter', '‘d', 'is', '’ve', 'before', 'fifty', 'seems', 'others', 'formerly', 'hers', 'although', 'for', 'done', 'six', 'none', 'during', 'go', 'i', 'however', 'back', 'therein', '‘m', 'unless', 'became', 'thereupon', 'always', 'quite', 'four', 'anyway', 'towards', 'then', 'thus', 'elsewhere', 'made', 'alone', 'your', 'just', 'ourselves', 'beyond', 'whenever', 'he', 'than', 'you', 'or', 'otherwise', 'they', \"'m\", 'once', 'whence', 'well', 'everywhere', 'hereby', 'whoever', 'except', 'regarding', 'twenty', 'several', 'not', 'serious', 'may', 'his', 'down', 'front', 'seeming', 'whither', 'further', 'to', 'we', 'those', 'our', 'nowhere', 'though', 'within', 'us', 'somehow', 'ours', 'least', 'that', 'hereafter', 'mine', 'because', 'another', 'nevertheless', 'moreover', '‘re', 'between', 'about', 'doing', 'as', 're', 'being', 'becomes', 'next', 'by', 'been', 'show', 'eleven', 'never', \"'d\", 'did', 'among', 'often', 'without', 'where', 'either', '’m', 'nor', 'would', 'how', 'empty', 'cannot', 'almost', 'someone', 'onto', 'name', 'nothing', 'so', 'be', 'should', 'whereafter', 'part', 'noone', 'only', 'various', 'an', 'at', 'when', 'own', 'really', 'again', 'but', 'me', 'if', 'some', 'sometimes', 'with', 'are', 'first', 'no', 'more', 'afterwards', 'this', 'yours', \"'s\", 'must', 'same', 'yourselves', \"'re\", '‘ve', 'herself', 'thereby', 'top', 'upon', 'fifteen', 'am', 'yourself', 'beside', 'indeed', 'please', 'sometime', 'everyone', 'twelve', 'herein', 'whole', 'were', 'get', 'can', \"'ll\", \"'ve\", 'could', 'seem', 'throughout', 'hence', 'rather', 'thence', 'them', 'somewhere', 'until', 'off', 'my', 'amount', 'above', 'behind', 'it', 'already', 'whether', 'less', 'across', 'yet', 'neither', 'thru', 'him', 'latter', 'whereby', '’ll', 'since', 'into', 'due', 'from', 'toward', 'used', 'anyhow', 'third', 'anything', 'along', 'former', 'sixty', 'after', 'their', 'any', 'all', 'around', 'each', 'whereas', 'here', 'side', 'both', 'enough', 'whatever', 'forty', 'while', 'seemed', 'become', 'becoming', 'n‘t', 'through', 'using', '‘ll', 'in', 'under', 'bottom', 'whom', 'even', 'wherein', 'every', 'everything', 'will', 'via', 'make', 'else', 'against', 'very', 'perhaps', 'most', 'one', 'such', 'namely', 'over', 'together', 'latterly', 'below', 'ca', 'three', 'up', '‘s', 'whose', 'ever', 'put', 'keep', 'she', 'anywhere', 'many', 'hereupon', 'beforehand', 'the', 'also', 'per', 'something', 'a', 'n’t', 'anyone', 'give', 'what', 'amongst', 'whereupon', 'and', 'much', 'was', 'nobody', 'move', 'does', 'too', 'out', 'call', 'meanwhile', 'myself', 'now', '’d', \"n't\", 'who', 'five', 'why', 'on', 'take', 'has', 'last', 'there', 'of', 'do', 'itself', 'full', 'its', 'had', 'nine', 'which', 'hundred', 'say', 'her'}\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc6f72d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[from, flight, Book]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u'Book me a flight from Bangalore to Goa')\n",
    "blr, goa = doc[5], doc[7]\n",
    "list(blr.ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d056f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[to, flight, Book]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(goa.ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffc63ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[3].is_ancestor(doc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b666bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1].is_ancestor(doc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c87211ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Booking of table belongs to restaurant\n",
      "Booking of taxi belongs to hotel\n",
      "Booking of table belongs to hotel\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Book a table at the restaurant and the taxi to the hotel')\n",
    "tasks = doc[2], doc[8] #(table, taxi)\n",
    "tasks_target = doc[5], doc[11] #(restaurant, hotel)\n",
    "for task in tasks_target:\n",
    "    for tok in task.ancestors:\n",
    "        if tok in tasks:\n",
    "            print(\"Booking of {} belongs to {}\".format(tok, task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2fd5c746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alomo\\anaconda3\\lib\\site-packages\\spacy\\displacy\\__init__.py:98: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c71bc786bd9d4a1ca8603f24870ddcd6-0\" class=\"displacy\" width=\"2150\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Book</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">table</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">restaurant</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">taxi</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">hotel</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-0\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-1\" stroke-width=\"2px\" d=\"M70,352.0 C70,177.0 390.0,177.0 390.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M390.0,354.0 L398.0,342.0 382.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M560.0,354.0 L568.0,342.0 552.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-3\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-4\" stroke-width=\"2px\" d=\"M595,352.0 C595,177.0 915.0,177.0 915.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,354.0 L923.0,342.0 907.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-5\" stroke-width=\"2px\" d=\"M420,352.0 C420,89.5 1095.0,89.5 1095.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,354.0 L1103.0,342.0 1087.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-7\" stroke-width=\"2px\" d=\"M420,352.0 C420,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-8\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,264.5 1610.0,264.5 1610.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1610.0,354.0 L1618.0,342.0 1602.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-9\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,264.5 1960.0,264.5 1960.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,354.0 L1812,342.0 1828,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-10\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,177.0 1965.0,177.0 1965.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c71bc786bd9d4a1ca8603f24870ddcd6-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1965.0,354.0 L1973.0,342.0 1957.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [06/Apr/2022 23:33:51] \"GET / HTTP/1.1\" 200 10070\n",
      "127.0.0.1 - - [06/Apr/2022 23:33:52] \"GET /favicon.ico HTTP/1.1\" 200 10070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "doc = nlp(u'Book a table at the restaurant and the taxi to the hotel')\n",
    "displacy.serve(doc, style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0b6d2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How [ 1.621378   -0.67405415 -1.2062874  -0.45594388  0.7263217 ]\n",
      "are [-1.202955   -0.23346695 -0.50031984 -0.8712524   0.2861007 ]\n",
      "you [ 0.22592095  0.05933836  0.2325796  -1.6726607   0.8675878 ]\n",
      "doing [-0.53632843  1.4226949  -0.05632752  1.3783771   0.41547692]\n",
      "today [0.18322672 0.61413574 0.5293832  0.9042447  1.2848978 ]\n",
      "? [-0.06557128 -0.21330667  0.04028246 -0.02445462 -1.6477724 ]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'How are you doing today?')\n",
    "for token in doc:\n",
    "    print(token.text, token.vector[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23f58d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.2.0/en_core_web_lg-3.2.0-py3-none-any.whl (777.4 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from en-core-web-lg==3.2.0) (3.2.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alomo\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (61.3.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.20.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.7.7)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.4.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (21.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: click<8.1.0 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.0.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.26.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.9.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\alomo\\appdata\\roaming\\python\\python39\\site-packages (from click<8.1.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\alomo\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.1.1)\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-3.2.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 23:35:22.544997: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-07 23:35:22.545034: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87b279f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0b3160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7628511777339915\n"
     ]
    }
   ],
   "source": [
    "hello_doc = nlp(u\"hello\")\n",
    "hi_doc = nlp(u\"hi\")\n",
    "hella_doc = nlp(u\"hallos\")\n",
    "print(hello_doc.similarity(hi_doc))\n",
    "#print(hello_doc.similarity(hella_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3092c9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9440999059835806"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GoT_str1 = nlp(u\"When will next season of Game of Thrones be releasing?\")\n",
    "GoT_str2 = nlp(u\"Game of Thrones next season release date?\")\n",
    "GoT_str1.similarity(GoT_str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9639d99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word car is 100% similar to word car\n",
      "Word car is 71% similar to word truck\n",
      "Word car is 23% similar to word google\n",
      "Word truck is 71% similar to word car\n",
      "Word truck is 100% similar to word truck\n",
      "Word truck is 15% similar to word google\n",
      "Word google is 23% similar to word car\n",
      "Word google is 15% similar to word truck\n",
      "Word google is 100% similar to word google\n"
     ]
    }
   ],
   "source": [
    "example_doc = nlp(u\"car truck google\")\n",
    "for t1 in example_doc:\n",
    "    for t2 in example_doc:\n",
    "        similarity_perc = int(t1.similarity(t2) * 100)\n",
    "        print(\"Word {} is {}% similar to word {}\".format(t1.text,similarity_perc, t2.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a3c600b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brexit\n",
      "is\n",
      "the\n",
      "impending\n",
      "withdrawal\n",
      "of\n",
      "the\n",
      "U.K.\n",
      "from\n",
      "the\n",
      "European\n",
      "Union\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Brexit is the impending withdrawal of the U.K. from the European Union.')\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5fa3073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_from pattern matched correctly. Printing values\n",
      "\n",
      "From: AsiaWorld-Expo., To: Hong Kong Airport\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"Book me a metro from Airport Station to Hong Kong Station.\"\n",
    "sentence2 = \"Book me a cab to Hong Kong Airport from AsiaWorld-Expo.\"\n",
    "import re\n",
    "from_to = re.compile('.* from (.*) to (.*)')\n",
    "to_from = re.compile('.* to (.*) from (.*)')\n",
    "from_to_match = from_to.match(sentence2)\n",
    "to_from_match = to_from.match(sentence2)\n",
    "if from_to_match and from_to_match.groups():\n",
    "    _from = from_to_match.groups()[0]\n",
    "    _to = from_to_match.groups()[1]\n",
    "    print(\"from_to pattern matched correctly. Printing values\\n\")\n",
    "    print(\"From: {}, To: {}\".format(_from, _to))\n",
    "elif to_from_match and to_from_match.groups():\n",
    "    _to = to_from_match.groups()[0]\n",
    "    _from = to_from_match.groups()[1]\n",
    "    print(\"to_from pattern matched correctly. Printing values\\n\")\n",
    "    print(\"From: {}, To: {}\".format(_from, _to))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaee815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
